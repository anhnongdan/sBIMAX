{
  "AbTesting": {
    "PluginDescription": "A/B Testing plugin",
    "NExperiments": "%s experiments",
    "ColumnConversionsPerVisit": "Conversions per visit",
    "ColumnRevenuePerVisit": "Revenue per visit",
    "ColumnOrdersPerVisit": "Orders per visit",
    "ColumnOrdersRevenuePerVisit": "Revenue per visit (from orders)",
    "ColumnDetectedEffect": "Detected effect",
    "ColumnDetectedEffectDocumentation": "The percentage of change compared to the original version. A positive detected effect means the variation is performing better than the original version while a negative detected effect means the variation is performing worse than the original version.",
    "ColumnRemainingVisitors": "Remaining visitors",
    "ColumnRemainingVisitorsDocumentation": "The number of additional unique visitors needed to enter the experiment in order to be able to draw conclusive results.",
    "ColumnSignificanceRate": "Statistical Significance",
    "ColumnSignificanceRateDocumentation": "The higher the statistical significance percentage, the more likely it is that the detected effect is real, repeatable and not due to randomness.",
    "ColumnTimeOnSite": "Time on website",
    "ColumnTotalConversions": "Total Conversions",
    "ColumnTotalConversionsPerVisit": "Conversions per visit",
    "ColumnTotalRevenue": "Total Revenue",
    "ColumnTotalRevenuePerVisit": "Revenue per visit",
    "ColumnVisitsDocumentation": "The number of visits which your experiment has received. All visits of a visitor who has entered the experiment once count towards this visit metric. Therefore this number is usually higher than the number of \"actively entered visits\".",
    "ColumnVisitsEnteredDocumentation": "The number of visits where a visitor has entered a target page of this experiment.",
    "ColumnUniqueVisitorsDocumentation": "The number of unique visitors that have entered your experiment.",
    "ColumnBounceRateDocumentation": "The percentage of visits that only had a single pageview. This means, that the visitor left the target page directly after entering the experiment.",
    "ColumnBouncesDocumentation": "The number of visits that started and ended when they entered an experiment target page. This means that the visitor left after viewing only a target page.",
    "ChooseExperiment": "Choose Experiment",
    "EcommerceOrders": "Ecommerce Orders",
    "EcommerceOrdersRevenue": "Ecommerce Orders Revenue",
    "ConclusionNoVariationRecordedYet": "No experiment activity has been recorded yet for any variation. It appears no visitor has entered the experiment. Maybe the experiment code needs to be embedded into your project.",
    "ConclusionWinningVariation": "There is a variation that is performing significantly better than the original version and it has met the expected Minimum Detectable Effect (MDE) of %1$s.",
    "ConclusionSignificantVariation": "There is a variation that is performing significantly better than the original version but it has not met the expected Minimum Detectable Effect (MDE) of %1$s.",
    "ConclusionLosingVariation": "There is a variation that is performing significantly worse than the original version.",
    "ConclusionNoVariationHasEnoughVisitors": "More visitors are needed to draw conclusive results.",
    "ConclusionNoVariationIsSignificant": "No variation has currently enough significance to draw conclusive results.",
    "ConclusionNoConclusion": "To draw conclusive results a variation needs to have no remaining visitors and be statistically significant.",
    "NameOriginalVariation": "Original",
    "ErrorCreateNoUrlDefined": "Please enter an URL to define on which pages the experiment should be activated.",
    "ErrorXNotProvided": "Please provide a value for \"%1$s\".",
    "ErrorXTooLong": "\"%1$s\" is too long, max %2$s characters are allowed.",
    "ErrorXTooLow": "\"%1$s\" is too low, minimum allowed value is %2$s.",
    "ErrorXTooHigh": "\"%1$s\" is too high, maximum allowed value is %2$s.",
    "ErrorXNotANumber": "\"%1$s\" has to be a number.",
    "ErrorXNotWhitelisted": "The value for \"%1$s\" is not allowed, use one of: %2$s.",
    "ErrorXContainsWhitespace": "The \"%1$s\" is not allowed to contain any whitespace.",
    "ErrorXContainsOnlyNumbers": "The \"%1$s\" is not allowed to contain only numbers, please use at least one letter.",
    "ErrorXOnlyAlNumDash": "Special characters for \"%1$s\" are not allowed.",
    "ErrorXNotInFuture": "\"%1$s\" must be in the future.",
    "ErrorXLaterThanY": "\"%1$s\" is later than \"%2$s\".",
    "ErrorXLaterThanYButEqual": "\"%1$s\" must be later than \"%2$s\" but they are equal.",
    "ErrorNotEnabledForExperiment": "The given \"%1$s\" is not enabled for this experiment.",
    "ErrorNotAnArray": "\"%1$s\" has to be an array.",
    "ErrorInnerIsNotAnArray": "Each \"%1$s\" within \"%2$s\" has to be an array.",
    "ErrorArrayMissingKey": "Missing array key \"%1$s\" in \"%2$s\" at position \"%3$s\".",
    "ErrorArrayMissingValue": "Missing value for array key \"%1$s\" in \"%2$s\" at position \"%3$s\".",
    "ErrorInvalidValue": "Invalid value for \"%1$s\" provided (\"%2$s\").",
    "ErrorExperimentDoesNotExist": "The requested experiment does not exist",
    "ErrorExperimentNameIsAlreadyInUse": "The experiment name is already in use by another experiment.",
    "ErrorExperimentAlreadyStarted": "The experiment cannot be started as it has been started already.",
    "ErrorExperimentCannotBeFinished": "This experiment cannot be finished as it has been finished already.",
    "ErrorExperimentCannotBeUpdatedBecauseArchived": "This experiment cannot be updated because it has been archived.",
    "ErrorVariationNameOriginalNotAllowed": "The variation name \"Original\" is a reserved variation name and cannot be used.",
    "ErrorNotValidUrl": "%1$s is not a valid URL. Make sure it starts for example with http://",
    "FieldSuccessMetricsLabel": "Select one or more success metrics",
    "FieldSuccessMetricsHelp1": "Success metrics help you to measure which of the variations is most successful and should be used in the future.",
    "FieldSuccessMetricsHelp2": "You can select one or multiple metrics to validate your hypothesis. Piwik will show a report comparing the different variations for each of your chosen metrics.",
    "FieldSuccessMetricsHelp3": "We recommend not to change any of your selected success metrics once an experiment has been started as it could lead to misinterpretations about the results.",
    "FieldIncludedTargetsLabel": "A visitor will enter the experiment when",
    "FieldIncludedTargetsHelp": "Targets allow you to define on which pages a visitor should enter this experiment. You can define one or more conditions. For example you can define to run an experiment whenever the URL or path equals a certain value and only if a certain URL parameter is present in the URL. A visitor will enter the experiment only when all conditions are met, not if only one of them is met. All conditions will be evaluated case insensitive.",
    "FieldExcludedTargetsLabel": "A visitor will not enter the experiment when",
    "FieldExcludedTargetsHelp": "By defining exclusions you can restrict on which pages a visitor will not enter this experiment. If a page matches any of these conditions, a visitor will not enter this experiment.",
    "FieldRedirectHelp1": "If you want to redirect your users to a different page when they enter this experiment, you can optionally configure a redirect URL for each variation including the original version. This is useful when you run an experiment in the browser using our JavaScript A/B testing framework. If you configure a URL, the \"Embed Code\" will automatically include the tracking code to perform a redirect so you only need to copy / paste the tracking code into your project and you are done.",
    "FieldRedirectHelp2": "If the redirects should not be executed on all pages, we recommend to make sure to specify on which pages a redirect should be executed under \"Target Pages\".",
    "FieldRedirectHelp3": "With our %sPHP Experiments framework%s you can also redirect users server side in your PHP project.",
    "ClickToCreateNewGoal": "Click here to create a new goal if a success metric is missing from the list.",
    "FormScheduleIntroduction": "By default an experiment will start as soon as this experiment is embedded into your project and will end as soon as you manually finish it. Alternatively you can schedule a start and finish date for this experiment.",
    "FieldScheduleExperimentStartLabel": "Start experiment on",
    "FieldScheduleExperimentStartHelp": "Leave the field empty if you want to start the experiment as soon as this experiment is embedded into your project. Make sure to finish configuring this experiment before the scheduled starting date. It is not recommended to change an experiment once it has been started as it could lead to misinterpretations about the results. The specified date will be assumed to be in %1$sUTC%2$s timezone.",
    "FieldScheduleExperimentFinishHelp": "Leave the field empty if you want to finish the experiment manually. If specified, this experiment will end automatically on the finish date. If you schedule the experiment to be finished automatically, make sure to run this experiment long enough so the results will be real and not due to randomness. The specified date will be assumed to be in %1$sUTC%2$s timezone.",
    "FieldScheduleExperimentFinishLabel": "Finish experiment on",
    "FieldPercentageParticipantsLabel": "Percentage of visitors who enter this experiment",
    "FieldPercentageParticipantsHelp": "Specify how many of your visitors should enter this experiment. If you select 70%, then 70% of all your visitors will enter this experiment and see either the original version or any variation. The other 30% won't enter the experiment and they will always see the original version.",
    "FieldPercentageVariationsLabel": "Percentage of traffic allocated to each variation",
    "FieldPercentageVariationsHelp": "It is recommended to show each variation to an equal amount of visitors (default) but you can change the percentage for each variation. The sum of all variations, including the original version should be 100%. Make sure some traffic is always allocated to the original version.",
    "FieldVariationsHelp": "Variations is the term for any new version (variation) you will test against the original (current) version. For example if you want to test different button colors against each other, create one variation for each color you want to compare. The variation names may be visible to your users in the source code or URL. Use only alpha numeric characters without any space or special characters. Max 50 characters can be used per variation name.",
    "ErrorVariationAllocatedNot100Traffic": "You have allocated more than 100% across all variations. Please lower the percentage of traffic allocated to your variations so the total is 100%.",
    "ErrorVariationAllocatedNotEnoughOriginal": "We detected the original version gets much less traffic than it would be by default. We recommend to increase the allocated traffic to the original version by lowering the percentage allocated to other variations.",
    "EqualsDateInYourTimezone": "This equals the following date in your timezone:",
    "Filter": "Filter",
    "CurrentTimeInUTC": "The current time in UTC is",
    "NoExperimentsFound": "There are no experiments with this status.",
    "DeleteExperimentInfo": "Delete experiment. It will not be possible to restore the experiment.",
    "ViewReportInfo": "View report for this experiment.",
    "ArchiveReportInfo": "Archive experiment. When you archive the experiment, it will not be deleted but the experiment will not be available anymore in the Report UI or for segmentation.",
    "ArchiveReportConfirm": "Are you sure you want to archive this experiment? The experiment will not be shown in the reports and cannot be used for segmentation once it has been archived.",
    "DeleteExperimentConfirm": "Are you sure you want to delete this experiment? Once an experiment has been deleted it will not be possible to restore it.",
    "UrlParameterValueToMatchPlaceholder": "Value to match for URL parameter name",
    "TargetPageTestTitle": "URL validator",
    "TargetPageTestLabel": "Enter a full URL including the protocol to check if a visitor will enter the experiment on this URL:",
    "TargetPageTestErrorInvalidUrl": "Enter a URL including a protocol.",
    "TargetPageTestUrlMatches": "A visitor will enter this experiment on this URL",
    "TargetPageTestUrlNotMatches": "A visitor will not enter this experiment on this URL",
    "ExperimentCreatedInfo1": "The experiment is scheduled to start on",
    "ExperimentCreatedInfo2": "and will run until",
    "ExperimentCreatedInfo3": "Make sure to make all needed changes before the experiment will start as it is not recommended to change the experiment once it has been started.",
    "ExperimentRunningInfo1": "This experiment has been started on",
    "ExperimentRunningInfo2": "and is scheduled to finish on",
    "ExperimentRunningInfo3": "We recommend not to make any change to a running experiment as it could lead to misinterpretations about the results.",
    "ExperimentFinishedInfo1": "This experiment is finished. We recommend not to make any change to a finished experiment as it could lead to misinterpretations about the results. ",
    "ExperimentFinishedInfo2": "Make sure to remove any embedded code for this experiment from your website, app or server.",
    "RelatedActions": "From here you might want to perform one of these actions",
    "ExperimentWillStartFromFirstTrackingRequest": "This experiment will start automatically as soon as this experiment is embedded into your project unless you have configured a scheduled date. Make sure to make all needed configurations upfront as it is not recommended to change an experiment once it has been started.",
    "Rule": "Rule",
    "RunExperimentWithJsClient": "Running an experiment in the browser with the Piwik JavaScript Tracker",
    "RunExperimentWithJsTracker": "Running an experiment for a website on the server",
    "RunExperimentWithOtherSDK": "Running an experiment in an application on iOS, Android, PHP, Java, C#, Python, ... ",
    "RunExperimentWithEmailCampaign": "Running an experiment in a campaign (eg. ad campaigns, email campagins)",
    "StatusRunning": "Running",
    "StatusArchived": "Archived",
    "StatusFinished": "Finished",
    "StatusCreated": "Created",
    "StatusActive": "Active",
    "Status": "Status",
    "StartDate": "Start Date",
    "FinishDate": "Finish Date",
    "Xhours": "%1$s hours",
    "1Hour": "1 hour",
    "1DayAnd1Hour": "1 day and 1 hour",
    "1DayAndYHours": "1 day and %1$s hours",
    "XDaysAnd1Hour": "%1$s days and 1 hour",
    "XDaysAndYHours": "%1$s days and %2$s hours",
    "NoActiveExperimentConfigured": "There is no active experiment.",
    "GettingStarted": "Getting started",
    "ExperimentIsFinishedPleaseRemoveCode": "As the experiment has been finished make sure to remove any embedded code for this experiment from your website, app or server.",
    "Redirects": "Redirects",
    "FieldExperimentNameHelp": "The name is a unique name for this experiment. The chosen name may be visible to your users in the source code or URL when running the experiment. Use only alpha numeric characters without any space or special characters. Max %1$s characters are allowed.",
    "FieldHypothesisHelp": "The hypothesis  explains what you predict to happen when you run the experiment, what the outcome will be and why it will happen. For example \"%1$sIf%2$s I change the buy now button color, %3$sthen%4$s I am hoping to sell more products %5$sbecause%6$s the button will be more visible.\". The hypothesis is an important step in defining your experiment and we recommend to take some time to think about it.",
    "FieldHypothesisPlaceholder": "eg 'If I change the buy now button color, then I am hoping to sell more products because the button will be more visible.'",
    "FieldDescriptionHelp": "This field is used to describe which things will be compared. For example \"Comparing blue and red buy now button color\".",
    "FieldDescriptionPlaceholder": "eg 'Comparing blue and red buy now button color'",
    "ActivateExperimentOnAllPages": "Visitors enter this experiment on any page",
    "ActiveExperimentOnSomePages": "Visitors enter this experiment when URL equals",
    "NavigationBack": "Back",
    "Schedule": "Schedule",
    "EmbedCode": "Embed code",
    "Definition": "Definition",
    "UpdatingData": "Updating data...",
    "FormCreateExperimentIntro": "An experiment lets you compare different versions and see which one performs better. These fields are required in order to create an experiment. Once the experiment has been created you will be able to customize it further.",
    "FieldConfidenceThresholdHelp": "The goal of an experiment is to make sure you collect enough data to confidently make changes based on the results of this experiment. The higher the number, the more likely it is that the results are real, repeatable, and not due to random chance.",
    "FieldMinimumDetectableEffectHelp1": "The minimum detectable effect is the relative minimum improvement that you expect to detect. For example if the conversion rate of a goal is currently 10%, and you expect a 20% MDE, then a variation will need to have a conversion rate of at least 12% in order to be a winning variation.",
    "FieldMinimumDetectableEffectHelp2": "If you expect a small effect we recommend to choose 10%, for a medium effect choose 40% and for a large effect choose 70%.",
    "FieldSuccessConditionsHelp": "We use the minimum detectable effect and the confidence threshold (statistical significance) to calculate the amount of visitors needed before you can be confident about the results. During the lifetime of an experiment you might see many different potentially winners that achieve the desired effect. However, you need to run the experiment long enough to ensure the detected effect is not due to randomness.",
    "NewExperimentTargetPageHelp": "By default, an experiment will be executed on all of your pages. Alternatively, you can choose to execute the experiment only on a specific page. If you specify a domain including an optional path the experiment will be only executed on that page. Once the experiment has been created you can include and exclude more pages.",
    "NeedHelp": "Need help?",
    "TargetPages": "Target Pages",
    "TrafficAllocation": "Traffic Allocation",
    "ActionViewReport": "View report",
    "ActionFinishExperiment": "Finish experiment",
    "ActionArchiveExperiment": "Archive experiment",
    "ActionArchiveExperimentSuccess": "Experiment successfully archived",
    "ActionEditExperimentAnyway": "Edit the experiment anyway",
    "ConfirmUpdateStartsExperiment": "The scheduled start date is in the past which means the experiment will start immediately. Are you sure you want to start this experiment? We recommend to not change an experiment once it has been started as it could lead to misinterpretations about the results.",
    "ConfirmFinishExperiment": "Are you sure you want to finish this experiment now? It will not be possible to start this experiment again once it has been finished. Don't forget to remove the code for this experiment from your project so your visitors will no longer enter the experiment.",
    "ExperimentRequiresUpdateBeforeViewEmbedCode": "You have unsaved changes for this experiment. Please save or cancel your changes to view the embed code.",
    "NoActiveExperiment": "There is no experiment running or finished.",
    "HowToGetStartedUserAccess": "Please ask a user with administration access to create a new experiment under the \"Administration\" menu.",
    "HowToGetStartedAdminAccess": "As an administrator you can %1$screate a new experiment%2$s.",
    "Preview": "Sample report",
    "ExperimentReportPreview": "Here is an example of a report that will be displayed once an experiment has been started.",
    "CreateNewExperiment": "Create new experiment",
    "CreateNewExperimentNow": "Create a new experiment now",
    "EditExperiment": "Edit experiment %s",
    "EditThisExperiment": "Edit experiment",
    "ManageExperiments": "Manage Experiments",
    "ManageExperimentsIntroduction": "An experiment lets you compare different versions and see which variation makes you more successful. Experiments are also known as A/B tests or split tests. In an experiment you show two or more variations to your visitors and the variation that performs better wins. When a visitor enters the experiment a variation will be randomly chosen and the visitor will see this variation for all subsequent visits. Experimenting in this way lets you maximise your success.",
    "MenuTitleExperiment": "Experiment \"%1$s\"",
    "ExperimentCreated": "The experiment has been successfully created. Now you can configure it further. We recommend to take a look at \"Success metrics\".",
    "ExperimentUpdated": "The experiment has been successfully updated.",
    "ExperimentStarted": "The experiment has been successfully started.",
    "ExperimentFinished": "The experiment has been successfully finished.",
    "Hypothesis": "Hypothesis",
    "MinimumDetectableEffectMDE": "Minimum Detectable Effect (MDE)",
    "ExpectedImprovement": "Expected Minimum Detectable Effect",
    "ConfidenceThreshold": "Confidence Threshold",
    "ReportStatusRunning": "The experiment has been running for %1$s since %2$s.",
    "ReportStatusFinished": "The experiment has been finished. It ran for %1$s from %2$s to %3$s.",
    "ReportWhenToDeclareWinner": "When to declare a winner? This experiment report might indicate a winning or losing variation but it is crucial to run experiments for at least one or two full business cycles. As user's behaviour varies at different times and days of the week we recommend to run experiments for full days or often better full weeks to ensure the detected effect is not due to randomness.",
    "ReportDateCannotBeChanged": "The date for an experiment report cannot be changed",
    "TargetTypeIsAny": "is any",
    "TargetTypeIsNot": "not %s",
    "TargetTypeEqualsExactly": "equals exactly",
    "TargetTypeEqualsExactlyInfo": "The value has to match exactly, including the URL protocol, search query and hash.",
    "TargetTypeEqualsSimple": "equals simple",
    "TargetTypeEqualsSimpleInfo": "The URL will match any protocol (eg http and https) with or without \"www.\" subdomain. Any trailing slash in the path as well as the search query and hash part of the URL will be ignored when matching the URL.",
    "TargetTypeContains": "contains",
    "TargetTypeExists": "exists",
    "TargetTypeStartsWith": "starts with",
    "TargetTypeRegExp": "matches the regular expression",
    "TargetTypeRegExpInfo": "Any regular expression, for example \"^(.*)test(.*)$\".",
    "TargetComparisionsCaseInsensitive": "All comparisons are evaluated case insensitive.",
    "TargetComparisons": "Comparisons",
    "TargetAttributeUrl": "URL",
    "TargetAttributePath": "Path",
    "FilesystemDirectory": "directory",
    "TargetAttributeUrlParameter": "URL Parameter",
    "TargetAttributeUrlParameterExample": "nameOfUrlParameter",
    "Manage": "Manage",
    "Experiment": "Experiment",
    "Experiments": "Experiments",
    "ExperimentName": "Experiment name",
    "ExperimentOverview": "Experiment overview",
    "Variation": "Variation",
    "Variations": "Variations",
    "VariationName": "Variation name",
    "VariationRedirectUrl": "Variation URL",
    "VariationPercentage": "Variation percentage",
    "PercentageParticipants": "Percentage participants",
    "SuccessConditions": "Success conditions",
    "SuccessMetric": "Success metric",
    "SuccessMetrics": "Success metrics",
    "SuccessMetricDetails": "Success metric details",
    "Target": "Target",
    "IncludedTargets": "Included targets",
    "ExcludedTargets": "Excluded targets",
    "AverageX": "Average %1$s",
    "VisitEnteredExperiment": "Visit entered experiment",
    "VisitsActivelyEntered": "Visits actively entered",
    "UniqueVisitorsActivelyEntered": "Unique visitors actively entered"
  }
}
